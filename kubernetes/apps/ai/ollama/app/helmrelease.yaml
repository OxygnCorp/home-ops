---
# yaml-language-server: $schema=https://k8s-schemas.oxygn.dev/helm.toolkit.fluxcd.io/helmrelease_v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama
spec:
  interval: 1h
  chartRef:
    kind: OCIRepository
    name: app-template
  install:
    remediation:
      retries: -1
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controllers:
      ollama:
        annotations:
          reloader.stakater.com/auto: "true"

        containers:
          app:
            image:
              repository: docker.io/ollama/ollama
              tag: 0.6.3

            env:
              TZ: America/Vancouver
              OLLAMA_HOST: 0.0.0.0
              OLLAMA_ORIGINS: "*"
              OLLAMA_MODELS: &modelPath /models
              OLLAMA_LOAD_TIMEOUT: "600"
              OLLAMA_CONTEXT_LENGTH: "8192"
              OLLAMA_GPU_ENABLED: "true"
              OLLAMA_GPU_TYPE: nvidia

            resources:
              requests:
                cpu: 200m
                memory: 1Gi
              limits:
                nvidia.com/gpu: 1
                memory: 6Gi

        pod:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: nvidia.com/gpu.present
                        operator: In
                        values:
                          - "true"

          nodeSelector:
            nvidia.com/gpu.present: "true"

          runtimeClassName: nvidia

    service:
      app:
        controller: *app
        ports:
          http:
            port: &port 11434

    route:
      app:
        hostnames:
          - "{{ .Release.Name }}.oxygn.dev"
        parentRefs:
          - name: internal
            namespace: kube-system
            sectionName: https
        rules:
          - backendRefs:
              - name: *app
                port: *port

    persistence:
      models:
        existingClaim: ollama-models
        advancedMounts:
          ollama:
            app:
              - path: *modelPath
      config:
        existingClaim: *app
        globalMounts:
          - path: /root/.ollama
